{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLxZKAAgv+HRsPz6HMaoap"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QS5EJSxzndlG","executionInfo":{"status":"ok","timestamp":1730632949064,"user_tz":-330,"elapsed":19128,"user":{"displayName":"Don","userId":"12066750055599047045"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import os"]},{"cell_type":"code","source":["# Hyperparameters\n","batch_size = 64\n","image_size = 64\n","nz = 256 # Size of the latent vector (noise input to the generator)\n","ngf = 550 # Size of feature maps in the generator\n","ndf = 50 # Size of feature maps in the discriminator\n","num_epochs = 25\n","lr = 0.0002\n","beta1 = 0.5 # Beta1 hyperparam for Adam optimizers\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"guY1VZmdveDn","executionInfo":{"status":"ok","timestamp":1730632968816,"user_tz":-330,"elapsed":472,"user":{"displayName":"Don","userId":"12066750055599047045"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(device)"],"metadata":{"id":"dC25BTnvveFM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730632970640,"user_tz":-330,"elapsed":17,"user":{"displayName":"Don","userId":"12066750055599047045"}},"outputId":"d0bcfb8a-dbb0-4064-8611-ad9da2406a0f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["transform = transforms.Compose([\n","transforms.Resize(image_size),\n","transforms.CenterCrop(image_size),\n","transforms.ToTensor(),\n","transforms.Normalize([0.5], [0.5], [0.5]), # Normalize the images between -1 and 1\n","])"],"metadata":{"id":"_2cjMFL5veHu","executionInfo":{"status":"ok","timestamp":1730632978234,"user_tz":-330,"elapsed":465,"user":{"displayName":"Don","userId":"12066750055599047045"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = dsets.ImageFolder(root=r\"/kaggle/input/skyview-an-aerial-landscape-dataset/Aeri\n","al_Landscapes\", #Update the path here\n","transform=transform)\n","os.makedirs(r'/kaggle/working/op')\n","save_folder =(r'/kaggle/working/op')"],"metadata":{"id":"JlhCuC_WveJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"Wx1T6kG-veMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","self.main = nn.Sequential(\n","nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n","nn.BatchNorm2d(ngf * 8),\n","nn.ReLU(True),\n","nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ngf * 4),\n","                           nn.ReLU(True),\n","nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ngf * 2),\n","nn.ReLU(True),\n","nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ngf),\n","nn.ReLU(True),\n","nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n","nn.Tanh()\n",")\n","def forward(self, input):\n","  return self.main(input)"],"metadata":{"id":"8_8730omveNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Discriminator model\n","class Discriminator(nn.Module):\n","def __init__(self):\n","super(Discriminator, self).__init__()\n","self.main = nn.Sequential(\n","nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n","nn.LeakyReLU(0.2, inplace=True),\n","nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ndf * 2),\n","nn.LeakyReLU(0.2, inplace=True),\n","nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ndf * 4),\n","nn.LeakyReLU(0.2, inplace=True),\n","nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","nn.BatchNorm2d(ndf * 8),\n","nn.LeakyReLU(0.2, inplace=True),\n","nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","nn.Sigmoid()\n",")\n","def forward(self, input):\n","  return self.main(input)"],"metadata":{"id":"TX6xBUF8veQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the generator and discriminator\n","netG = Generator().to(device)\n","netD = Discriminator().to(device)\n","# Loss function and optimizers\n","criterion = nn.BCELoss()\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"46X83_WJxQmp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","with tqdm(total=len(dataloader), desc=f\"Epoch [{epoch+1}/{num_epochs}]\", unit=\"batch\n","\", colour=\"green\", smoothing=0.1) as pbar:\n","for i, data in enumerate(dataloader, 0):\n","# Update Discriminator network\n","netD.zero_grad()\n","real_images = data[0].to(device)\n","b_size = real_images.size(0)\n","label = torch.full((b_size,), 1., device=device)\n","output = netD(real_images).view(-1)\n","errD_real = criterion(output, label)\n","errD_real.backward()\n","# Generate fake images\n","noise = torch.randn(b_size, nz, 1, 1, device=device)\n","fake_images = netG(noise)\n","label.fill_(0.)\n","output = netD(fake_images.detach()).view(-1)\n","errD_fake = criterion(output, label)\n","errD_fake.backward()\n","optimizerD.step()\n","# Update Generator network\n","netG.zero_grad()\n","label.fill_(1.)\n","output = netD(fake_images).view(-1)\n","errG = criterion(output, label)\n","errG.backward()\n","optimizerG.step()\n","# Update progress bar\n","pbar.set_postfix({\n","\"Loss_D\": f\"{(errD_real + errD_fake).item():.4f}\",\n","\"Loss_G\": f\"{errG.item():.4f}\"\n","})\n","pbar.update(1) # Update the progress bar for each batch\n","# Save fake images after every epoch\n","with torch.no_grad():\n","fake_images = netG(fixed_noise).detach().cpu()\n","vutils.save_image(fake_images,os.path.join(save_folder, f\"fake_images_epoch_{epoch}.png\"), normalize=True)\n"],"metadata":{"id":"itLqKhPhxQoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["real_batch = next(iter(dataloader))\n","plt.figure(figsize=(10, 10))\n","plt.subplot(1, 2, 1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, norma\n","lize=True).cpu(), (1, 2, 0)))\n","plt.subplot(1, 2, 2)\n","plt.axis(\"off\")\n","plt.title(\"Generated Images\")\n","plt.imshow(np.transpose(vutils.make_grid(fake_images, padding=2, normalize=True).cpu(),\n","(1, 2, 0)))\n","plt.show()"],"metadata":{"id":"VJoIbmGjxQsH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Idojdx8gveTc"},"execution_count":null,"outputs":[]}]}